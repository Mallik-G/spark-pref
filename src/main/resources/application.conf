akka {
  loglevel = INFO
  stdout-loglevel = INFO
  akka.loggers = ["akka.event.slf4j.Slf4jLogger"]
}

actor {
  duration = 10
  retries = 10  
  timeout = 10
}

#
# Access to cassandra is provided by Datastax' spark-cassandra-connector; the respective
# configuration parameters can be retrieved from here: 
#
# https://github.com/datastax/spark-cassandra-connector/blob/master/doc/0_quick_start.md
#
cassandra {
  spark.cassandra.connection.host="127.0.0.1"
}

elastic {
  es.nodes="localhost"
  es.port="9200"
  es.resource=""                
  es.query=""                          
}

hbase {
  spark.hbase.host="127.0.0.1"
}

#
# Specification of text files or parquet stores to read 'event' 
# and also 'item' based data sources. 
#
input {
  event=""
  item=""
}

mongo {
  mongo.input.uri="mongodb://127.0.0.1:27017/beowulf.input"
}

mysql {
  url="127.0.0.1:8889"
  database="analytics"    
  user="root"
  password="root" 
}

#
# Specification of text files or parquet stores to save 'event' and also 'item'
# based user preference ratings.
#
output {
  event=""
  item=""
}

redis {
  host="127.0.0.1"
  port="6379"
}

rest {
  host="127.0.0.1"
  port=9000
}

spark {
  spark.executor.memory="4g"
  spark.kryoserializer.buffer.mb="256"
}